## 配置项config

- broker.id：Broker 的唯一 ID，用于标识集群中的 Kafka 节点。每个节点的 broker.id 必须唯一。
- listeners：Kafka Broker 的监听地址，指定 Kafka 应该在哪些地址和端口上监听客户端的连接。
- log.dirs: 指定存储 Kafka 数据（日志文件）的目录，支持多个目录。Kafka 会将数据存储在这些目录中。
- zookeeper.connect: 指定 ZooKeeper 集群的连接字符串，Kafka 使用 ZooKeeper 来管理集群状态。
  
- advertised.listeners: 客户端连接时使用的地址和端口，通常用于 Docker 或其他容器化环境，Broker 向客户端"广播"它的可访问地址。
- num.network.threads: Kafka 网络线程的数量，处理来自客户端的网络请求。
- num.io.threads: Kafka IO 线程的数量，处理磁盘 IO 任务。
- socket.send.buffer.bytes: Socket 发送缓冲区的大小。
- socket.receive.buffer.bytes: Socket 接收缓冲区的大小。
- socket.request.max.bytes: 客户端请求的最大字节数。

- log.retention.hours: Kafka 日志保留的最长时间，超过该时间的日志文件将被删除。可以设置为小时 (log.retention.hours) 或分钟 (log.retention.minutes)。
- log.retention.bytes: 每个 Partition 的日志最大字节数，超出该大小后 Kafka 将删除旧的日志。
- log.segment.bytes: Kafka 日志分段文件的大小。达到此大小后，Kafka 会将消息写入新的分段文件。
- log.segment.ms: 日志分段的最大时间限制。即使未达到 log.segment.bytes，也会在设定的时间间隔后分割日志文件。

- num.partitions: 创建 Topic 时的默认分区数量。
- default.replication.factor: 创建 Topic 时的默认副本因子。
- min.insync.replicas: 消息被认为成功写入的最少同步副本数量，确保数据的可靠性。
- unclean.leader.election.enable: 是否允许非同步副本被选举为 Leader。设为 true 可能会导致数据丢失。
- replica.lag.time.max.ms: 副本落后 Leader 的最大时间，超出该时间的副本将被视为不同步的副本。

- auto.create.topics.enable: 是否允许 Kafka 自动创建 Topic。生产者或消费者如果请求了一个不存在的 Topic，Kafka 会自动创建它。
- message.max.bytes: Kafka 生产者可以发送的消息的最大字节数。如果消息太大，会被拒绝。
- replica.fetch.max.bytes: 副本从 Leader 副本获取消息时的最大字节数。
- fetch.min.bytes: 消费者从 Kafka Broker 中获取的最小数据量（字节）。Broker 会在达到该字节数后才发送数据给消费者。
- fetch.max.wait.ms: 消费者最多等待多久以获得消息，即使没有足够的消息达到 fetch.min.bytes

- delete.topic.enable: 允许删除 Topic 的设置。如果为 false，则无法删除 Kafka 的 Topic。

- enable.auto.commit=true 时，消费者会自动定期提交它所消费的偏移量。
- auto.commit.interval.ms: 控制偏移量提交的频率。默认值通常是 5000 毫秒（5秒），这意味着每隔 5 秒，Kafka 消费者会自动提交当前的偏移量。
- auto.offset.reset: Kafka 消费者配置中的一个参数，它定义了消费者在没有可用偏移量时，或者当前偏移量在服务器上不存在（通常是因为该偏移量太老，已被 Kafka 清理掉）时应该从哪个位置开始消费消息。
  + earliest：消费者将从主题的最早的消息开始消费（也就是偏移量最小的地方）。适用于希望重新消费所有可用消息的场景。
  + latest（默认值）：消费者将从最新的消息开始消费（也就是从新生产的消息开始）。适用于希望只处理新到达的消息的场景。
  + none：如果没有找到之前提交的偏移量，消费者将抛出一个错误并停止。适用于偏移量必须存在的场景。
  + anything else：如果设置了其他无效的值，会抛出异常


## bin目录脚本

1. kafka-server-start.sh  
用于启动 Kafka Broker。这个脚本会根据给定的配置文件启动一个 Kafka 服务器。

示例：
```
bin/kafka-server-start.sh config/server.properties
```
这个命令会使用 server.properties 文件中的配置启动 Kafka 服务器。

2. kafka-server-stop.sh
用于停止 Kafka Broker。通过此脚本可以安全地关闭 Kafka 实例。

3. kafka-topics.sh
管理 Kafka 主题的脚本，可以创建、删除、列出和描述 Kafka 主题。  
```
创建主题：
bin/kafka-topics.sh --create --topic my_topic --bootstrap-server localhost:9092 --partitions 3 --replication-factor 2
创建一个名为 my_topic 的主题，设置为 3 个分区，副本因子为 2。

列出所有主题：
bin/kafka-topics.sh --list --bootstrap-server localhost:9092
列出 Kafka 集群中所有的主题。

查看主题详情：
bin/kafka-topics.sh --describe --topic my_topic --bootstrap-server localhost:9092
查看名为 my_topic 的主题的详细信息。
```

4. kafka-console-producer.sh
这是一个命令行工具，用于向 Kafka 主题发送消息。它允许你在命令行中作为生产者发送数据到 Kafka 主题。

```
bin/kafka-console-producer.sh --topic my_topic --bootstrap-server localhost:9092
启动生产者并向 my_topic 主题发送消息。在运行此命令后，终端将等待输入，你可以输入消息，按回车后消息将发送到 Kafka。
```

5. kafka-console-consumer.sh
用于从 Kafka 主题消费消息的命令行工具。它允许你在终端中作为消费者消费消息。

```
从头开始消费消息：
bin/kafka-console-consumer.sh --topic my_topic --from-beginning --bootstrap-server localhost:9092
从 my_topic 主题的开头开始消费消息。


只消费最新消息：
bin/kafka-console-consumer.sh --topic my_topic --bootstrap-server localhost:9092
仅从当前位置消费新的消息。
```

6. kafka-consumer-groups.sh
用于管理和查看 Kafka 消费者组的工具。可以查看消费者组的 Offset、Lag、成员等信息。

```
bin/kafka-consumer-groups.sh --list --bootstrap-server localhost:9092
列出集群中的所有消费者组。

查看消费者组详情：
bin/kafka-consumer-groups.sh --describe --group my_group --bootstrap-server localhost:9092
查看消费者组 my_group 的详细信息，包括 Offset 和 Lag。
```

## 消费者分组消费机制

### group.instance.id
  在 Kafka 中，group.instance.id 是消费者组中的一个配置项，主要用于实现静态成员管理（Static Membership），从而优化消费者的重新平衡过程。  

背景：  
      在 Kafka 的消费者组中，重新平衡（rebalance）是当消费者加入或离开组时进行的分区重新分配操作。
    然而，传统的消费者组是动态的(instance.id是动态的，会变)，消费者的生命周期是短暂的，每当消费者崩溃或断开连接时，Kafka 都会触发重新平衡。这会导致延迟和中断。  

      为了解决这个问题，引入了 静态成员（Static Membership） 的概念，通过配置 group.instance.id，每个消费者在组内有一个`固定的标识符（ID）`，
    即使消费者暂时断开连接，Kafka 也不会立即认为它已经离开（因为instance.id不变），而是允许它在指定的时间内重新连接，不触发重新平衡（rebalance）。  

作用：  
      group.instance.id：消费者在 Kafka 组中的唯一标识符。如果配置了这个值，消费者在加入组时会使用它来标识自己。即使消费者临时断开，Kafka 不会立即从组中移除它，只要它在允许的时间内重新连接，就不会触发重新平衡（rebalance）。  

主要优点：  
1. 减少重新平衡：当消费者短时间内断开连接后重新连接时，Kafka 不会认为该消费者已经离开，因此不会触发重新平衡（rebalance），避免消费延迟。
2. 提升可用性：在断线重连时，消费者可以继续使用之前分配的分区，而不需要重新进行分区分配。
3. 优化分区分配稳定性：使用静态成员 ID 能保证分区的所有权在短时间内不变，特别适合长时间运行的消费者。

### 如果kafka把offset弄丢了，怎么办？
配置项 auto.offset.reset: Kafka 消费者配置中的一个参数，它定义了消费者在没有可用偏移量时，或者当前偏移量在服务器上不存在（通常是因为该偏移量太老，已被 Kafka 清理掉）时应该从哪个位置开始消费消息。
  
  + earliest：消费者将从主题的最早的消息开始消费（也就是偏移量最小的地方）。适用于希望重新消费所有可用消息的场景。
  + latest（默认值）：消费者将从最新的消息开始消费（也就是从新生产的消息开始）。适用于希望只处理新到达的消息的场景。
  + none：如果没有找到之前提交的偏移量，消费者将抛出一个错误并停止。适用于偏移量必须存在的场景。
  + anything else：如果设置了其他无效的值，会抛出异常
  
### kafka记录的offset不对，怎么办？
如果存在这种情况，可以先把kafka的offset取出来，存到redis/DB等中（可以防止kafka丢失offset），自己管理每个partition的offset。  
  
在消费kafka数据时，先比较kafka和client记录的offset，如果client.offset > kafka.offset, 说明可能消费/处理过，kafka没把offset推进，那么就不处理该消息。
  
## 生产者拦截器
涉及配置参数： interceptor.classes

## 消息序列化机制
client可以根据自己的规则去序列化数据

## 消息分区路由机制

### 生产者
涉及配置参数： partitioner.class, 用于定义消息发送到 Kafka 时，如何选择分区的策略。不同的分区策略会影响 Kafka 消息在不同分区上的分布方式。  
在 Kafka 中，生产者将消息发送到主题时，通常会根据某种规则决定将消息存储到哪一个分区。这就是 partitioner 的工作：根据消息键、主题、或其他因素，选择一个目标分区。  

其可选项为：  
1. org.apache.kafka.clients.producer.internals.DefaultPartitioner（默认分区器）  
      其工作原理如下：  
      如果消息有指定的key，则使用该 key 进行哈希，计算出要使用的分区。
      
      如果消息没有 key，则使用 轮询策略（Round Robin, RoundRobinPartitioner）将消息均匀地分布到不同分区。  
      
      使用此策略时，可以保证相同 key 的消息总是会进入相同的分区，从而保证消息的顺序性。

2. org.apache.kafka.clients.producer.internals.StickyPartitioner  
      StickyPartitioner 是 Kafka 2.4.0 中引入的一种新的默认分区器，专门用于处理没有 key 的消息。
      
      其策略是：当没有提供 key 时，所有消息在一段时间内会被发送到同一个分区，以减少网络请求的数量，提高性能。只有当该批消息发送完毕后，才会切换到下一个分区。  
      
3. 自定义分区器  
      Kafka 允许你定义自己的分区器。你可以根据业务需求来设计分区策略，例如按时间分区、按地域分区，或按其他业务规则。  
      要使用自定义分区器，你需要实现 org.apache.kafka.clients.producer.Partitioner 接口，并在 partitioner.class 中配置你的类  
```
/*
在 Golang 中使用 sarama 客户端时，Kafka 提供了灵活的分区策略配置，你可以通过实现自定义的分区器来控制消息分发到不同分区的方式。

自定义分区器需要实现 sarama.Partitioner 接口，该接口有两个主要方法：

Partition(message *sarama.ProducerMessage, numPartitions int32) (int32, error)：用于定义如何选择分区。
RequiresConsistency() bool：用于指定是否保证同一个 key 的消息始终发送到相同的分区。
*/
package main

import (
    "fmt"
    "hash/fnv"
    "log"
    "sync/atomic"

    "github.com/IBM/sarama"
)

// MyCustomPartitioner 自定义的分区器
type MyCustomPartitioner struct {
    counter int32
}

// Partition 根据消息 key 来选择分区，如果没有 key，则轮询分区
func (p *MyCustomPartitioner) Partition(message *sarama.ProducerMessage, numPartitions int32) (int32, error) {
    if message.Key != nil {
        // 如果有 key，则根据 key 的哈希值选择分区
        keyBytes, err := message.Key.Encode()
        if err != nil {
            return -1, err
        }
        hashValue := hash(keyBytes)
        return int32(hashValue % uint32(numPartitions)), nil
    }
    // 如果没有 key，则轮询选择分区
    partition := atomic.AddInt32(&p.counter, 1) % numPartitions
    return partition, nil
}

// RequiresConsistency 保证相同的 key 总是选择同一个分区
func (p *MyCustomPartitioner) RequiresConsistency() bool {
    return true
}

// hash 函数，使用 FNV 算法对 key 进行哈希
func hash(key []byte) uint32 {
    h := fnv.New32a()
    _, _ = h.Write(key)
    return h.Sum32()
}

func main() {
    // 配置 sarama 客户端
    config := sarama.NewConfig()
    config.Producer.Partitioner = func(topic string) sarama.Partitioner {
        return &MyCustomPartitioner{}
    }

    // 创建同步生产者
    producer, err := sarama.NewSyncProducer([]string{"localhost:9092"}, config)
    if err != nil {
        log.Fatalf("Failed to start Sarama producer: %v", err)
    }
    defer producer.Close()

    // 创建带 key 和不带 key 的消息
    for i := 0; i < 10; i++ {
        var key sarama.Encoder
        if i%2 == 0 {
            key = sarama.StringEncoder(fmt.Sprintf("key-%d", i))
        }

        message := &sarama.ProducerMessage{
            Topic: "test-topic",
            Key:   key,
            Value: sarama.StringEncoder(fmt.Sprintf("This is message %d", i)),
        }

        partition, offset, err := producer.SendMessage(message)
        if err != nil {
            log.Fatalf("Failed to send message: %v", err)
        }

        fmt.Printf("Message %d is stored in partition %d, offset %d\n", i, partition, offset)
    }
}
```

### 消费者
partition.assignment.strategy 是 Kafka 的一个消费者组配置项，用于指定在消费者组内进行分区分配时所采用的策略。它定义了当新的消费者加入或离开时，如何将分区分配给消费者组中的各个消费者。  

常见的分区分配策略  
1. Range 分配策略 (RangeAssignor):  
      Range 是 Kafka 的默认分区分配策略。
      
      每个消费者根据顺序连续获取一定数量的分区。例如，如果有 3 个分区和 2 个消费者，Range 会将前两个分区分配给第一个消费者，最后一个分区分配给第二个消费者。   
      
      适合对顺序敏感的场景，但分区可能会不均匀分配。    
  
2. RoundRobin 分配策略 (RoundRobinAssignor):
  
      RoundRobin 分配策略是将分区循环地分配给消费者组内的消费者。
      
      例如，如果有 3 个分区和 2 个消费者，分配可能是第一个分区分配给第一个消费者，第二个分区分配给第二个消费者，第三个分区再分配给第一个消费者。  
        
      适合希望分区均匀分配的场景，但在不同消费者之间可能会打乱顺序。  
  
3. Sticky 分配策略 (StickyAssignor):

      StickyAssignor 是一种保持分区分配稳定性的策略，尽可能地避免在分配时将分区从一个消费者移动到另一个消费者。  
       
      在消费者组变动较小的情况下，它能够最大限度地保持分区在相同的消费者上，从而减少重平衡的影响。  
       
      适用于希望减少分区重新分配次数的场景。  
   
4. CooperativeSticky 分配策略 (CooperativeStickyAssignor):

      CooperativeStickyAssignor 是 StickyAssignor 的增强版本。它允许在消费者组成员变化时进行逐步重新分配，以减少消费者的停机时间和分区重新平衡对组的影响。
      适用于需要最低影响、最小化重平衡影响的场景。

5. 自定义分配策略
   实现相关接口

配置示例
```
使用 RangeAssignor
partition.assignment.strategy=org.apache.kafka.clients.consumer.RangeAssignor

使用 RoundRobinAssignor
partition.assignment.strategy=org.apache.kafka.clients.consumer.RoundRobinAssignor

组合使用多种策略：
partition.assignment.strategy=org.apache.kafka.clients.consumer.CooperativeStickyAssignor,org.apache.kafka.clients.consumer.RangeAssignor
Kafka 会根据策略列表的优先级，从上到下选择一个可用的策略。

使用 Golang sarama 实现自定义分配策略
在 sarama 客户端中，可以通过设置消费者配置来选择分区分配策略。sarama 默认使用 Kafka 的分区分配机制，支持 Range 和 RoundRobin 两种策略。
config := sarama.NewConfig()
config.Consumer.Group.Rebalance.Strategy = sarama.BalanceStrategyRoundRobin
这会告诉 Kafka 使用 RoundRobin 策略来分配分区。你也可以通过类似的方式选择 Range 分配策略：
config.Consumer.Group.Rebalance.Strategy = sarama.BalanceStrategyRange
```

适用场景
1. RangeAssignor：适合需要顺序消费分区的场景。
2. RoundRobinAssignor：适合需要均匀分配分区的场景，特别是在分区数远大于消费者数时效果较好。
3. StickyAssignor/CooperativeStickyAssignor：适合希望减少分区重新分配次数，最大化稳定性的场景。

## 生产者消息缓存机制
    kafka生产者为了避免高并发请求对服务端造成过大压力，每次发消息时并不是一条一条发往服务端，而是增加一个高速缓存，将消息集中到缓存后，批量进行发送，这种缓存机制也是高并发处理时非常常用的一种机制。
    kafka的消息缓存机制涉及到kafka.producer中的2个关键组件：accumulator 和 sender

两者的协作流程：  
    消息进入 Accumulator：生产者调用 send() 方法时，消息首先被放入 Accumulator 中。Accumulator 按照分区对消息进行分类，等待条件满足时批量发送。  
    Sender 从 Accumulator 获取消息：后台的 Sender 线程不断检查 Accumulator，查找是否有可以发送的批次。一旦发现满足条件的消息（满足 batch.size 或 linger.ms），Sender 就会将它们打包成一个 ProducerBatch，然后发送到 Kafka Broker。  
    消息发送：Sender 通过网络将消息发送到对应的 Kafka Broker，并根据配置的 acks 策略决定如何确认消息发送的成功。  
    处理回调：Sender 发送完消息后，会处理相应的回调逻辑（如成功或失败的回调），并将结果反馈给客户端。  

相关配置参数：
1. batch.size：控制每个消息批次的大小。当累积的消息字节数达到此限制时，Producer 会将消息发送到 Kafka Broker。
2. linger.ms：Producer 在等待更多消息批量发送时的等待时间，即使消息没有达到 batch.size，在达到 linger.ms 时间后也会发送消息。较高的 linger.ms 值可以增加批量大小，从而提高吞吐量，但也会增加延迟。默认值为0毫秒，意味着立即发送。
3. acks：控制消息确认的策略。设置为 1 表示 Kafka Broker 接收到消息后立即返回确认；设置为 all 或 -1 则要求所有参与复制的节点都确认接收到消息才返回确认。
4. retries：控制重试次数，如果消息发送失败，Sender 会根据 retries 的配置进行重试
5. max.request.size: 控制发送到服务器的最大请求大小。默认值为1048576字节（1MB）
6. buffer.memory: 控制生产者可以用来缓冲等待发送的消息总量的内存大小

   
## 生产者发送应答机制
    Kafka 生产者发送应答机制（Producer Acknowledgement Mechanism）决定了 Kafka Broker 在接收到消息后如何给生产者发送确认（acknowledgment）。通过配置生产者的 acks 参数，Kafka 生产者可以控制消息的可靠性和延迟之间的权衡。  
    
    Kafka 提供了三种主要的应答模式：
      - acks=0（不等待应答）
        机制：生产者发送消息后不等待 Kafka Broker 的任何应答，即消息一旦发送就被认为成功，即使 Broker 还没有接收到消息，也不会发送确认回给生产者。
        优点：速度快，具有最低的延迟，因为生产者不需要等待任何应答。
        缺点：可靠性最低。消息有可能没有成功发送到 Kafka Broker，而生产者依然认为消息发送成功，可能会导致数据丢失。
        适用场景：
        非关键应用，追求极低延迟并且可以接受数据丢失的场景。
      - acks=1（Leader 接收应答）
        机制：当 Kafka 生产者发送消息后，Leader 副本接收到消息后会立即给生产者发送确认应答。这意味着只要 Leader 成功接收了消息，生产者就认为消息发送成功。
        优点：比 acks=0 更可靠，因为至少 Kafka 集群的 Leader 副本接收了消息。延迟相对较低。
        缺点：如果 Leader 副本接收消息后崩溃，且其他副本还没有复制这条消息，则可能导致消息丢失。
        适用场景：
        适用于大多数场景，在性能和数据可靠性之间取得平衡。对少量的数据丢失可以接受。
      - acks=all 或 acks=-1（所有副本应答）
        机制：生产者发送的消息必须被**所有副本（包括 Leader 和所有 ISR 副本）**成功接收后，Kafka 才会给生产者发送确认应答。Kafka 只在确认消息已经被所有的副本复制后，才认为消息发送成功。
        优点：这是最可靠的方式。保证消息不会因为 Leader 崩溃而丢失，因为至少一个同步副本已经接收了消息。
        缺点：延迟较高，因为需要等待所有副本都接收到消息后才返回确认。吞吐量可能会降低。
        适用场景：
        适用于对数据一致性要求极高的场景，不能接受任何消息丢失的业务场景。

    相关配置参数
      - acks：决定 Kafka Producer 在发送消息后等待哪些副本的应答。可以是 0（不等待）、1（只等待 Leader 副本）、all（等待所有副本）。
      - min.insync.replicas：配合 acks=all 使用，指定最少有多少个副本必须处于同步状态，才能认为消息发送成功。如果同步副本数小于此值，则消息发送会失败。

    
## 生产者消息幂等性
