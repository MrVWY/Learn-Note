## 配置项config

- broker.id：Broker 的唯一 ID，用于标识集群中的 Kafka 节点。每个节点的 broker.id 必须唯一。
- listeners：Kafka Broker 的监听地址，指定 Kafka 应该在哪些地址和端口上监听客户端的连接。
- log.dirs: 指定存储 Kafka 数据（日志文件）的目录，支持多个目录。Kafka 会将数据存储在这些目录中。
- zookeeper.connect: 指定 ZooKeeper 集群的连接字符串，Kafka 使用 ZooKeeper 来管理集群状态。
  
- advertised.listeners: 客户端连接时使用的地址和端口，通常用于 Docker 或其他容器化环境，Broker 向客户端"广播"它的可访问地址。
- num.network.threads: Kafka 网络线程的数量，处理来自客户端的网络请求。
- num.io.threads: Kafka IO 线程的数量，处理磁盘 IO 任务。
- socket.send.buffer.bytes: Socket 发送缓冲区的大小。
- socket.receive.buffer.bytes: Socket 接收缓冲区的大小。
- socket.request.max.bytes: 客户端请求的最大字节数。

- log.retention.hours: Kafka 日志保留的最长时间，超过该时间的日志文件将被删除。可以设置为小时 (log.retention.hours) 或分钟 (log.retention.minutes)。
- log.retention.bytes: 每个 Partition 的日志最大字节数，超出该大小后 Kafka 将删除旧的日志。
- log.segment.bytes: Kafka 日志分段文件的大小。达到此大小后，Kafka 会将消息写入新的分段文件。
- log.segment.ms: 日志分段的最大时间限制。即使未达到 log.segment.bytes，也会在设定的时间间隔后分割日志文件。

- num.partitions: 创建 Topic 时的默认分区数量。
- default.replication.factor: 创建 Topic 时的默认副本因子。
- min.insync.replicas: 消息被认为成功写入的最少同步副本数量，确保数据的可靠性。
- unclean.leader.election.enable: 是否允许非同步副本被选举为 Leader。设为 true 可能会导致数据丢失。
- replica.lag.time.max.ms: 副本落后 Leader 的最大时间，超出该时间的副本将被视为不同步的副本。

- auto.create.topics.enable: 是否允许 Kafka 自动创建 Topic。生产者或消费者如果请求了一个不存在的 Topic，Kafka 会自动创建它。
- message.max.bytes: Kafka 生产者可以发送的消息的最大字节数。如果消息太大，会被拒绝。
- replica.fetch.max.bytes: 副本从 Leader 副本获取消息时的最大字节数。
- fetch.min.bytes: 消费者从 Kafka Broker 中获取的最小数据量（字节）。Broker 会在达到该字节数后才发送数据给消费者。
- fetch.max.wait.ms: 消费者最多等待多久以获得消息，即使没有足够的消息达到 fetch.min.bytes

- delete.topic.enable: 允许删除 Topic 的设置。如果为 false，则无法删除 Kafka 的 Topic。

- enable.auto.commit=true 时，消费者会自动定期提交它所消费的偏移量。
- auto.commit.interval.ms 控制偏移量提交的频率。默认值通常是 5000 毫秒（5秒），这意味着每隔 5 秒，Kafka 消费者会自动提交当前的偏移量。
