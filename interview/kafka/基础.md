## 配置项config

- broker.id：Broker 的唯一 ID，用于标识集群中的 Kafka 节点。每个节点的 broker.id 必须唯一。
- listeners：Kafka Broker 的监听地址，指定 Kafka 应该在哪些地址和端口上监听客户端的连接。
- log.dirs: 指定存储 Kafka 数据（日志文件）的目录，支持多个目录。Kafka 会将数据存储在这些目录中。
- zookeeper.connect: 指定 ZooKeeper 集群的连接字符串，Kafka 使用 ZooKeeper 来管理集群状态。
  
- advertised.listeners: 客户端连接时使用的地址和端口，通常用于 Docker 或其他容器化环境，Broker 向客户端"广播"它的可访问地址。
- num.network.threads: Kafka 网络线程的数量，处理来自客户端的网络请求。
- num.io.threads: Kafka IO 线程的数量，处理磁盘 IO 任务。
- socket.send.buffer.bytes: Socket 发送缓冲区的大小。
- socket.receive.buffer.bytes: Socket 接收缓冲区的大小。
- socket.request.max.bytes: 客户端请求的最大字节数。

- log.retention.hours: Kafka 日志保留的最长时间，超过该时间的日志文件将被删除。可以设置为小时 (log.retention.hours) 或分钟 (log.retention.minutes)。
- log.retention.bytes: 每个 Partition 的日志最大字节数，超出该大小后 Kafka 将删除旧的日志。
- log.segment.bytes: Kafka 日志分段文件的大小。达到此大小后，Kafka 会将消息写入新的分段文件。
- log.segment.ms: 日志分段的最大时间限制。即使未达到 log.segment.bytes，也会在设定的时间间隔后分割日志文件。

- num.partitions: 创建 Topic 时的默认分区数量。
- default.replication.factor: 创建 Topic 时的默认副本因子。
- min.insync.replicas: 消息被认为成功写入的最少同步副本数量，确保数据的可靠性。
- unclean.leader.election.enable: 是否允许非同步副本被选举为 Leader。设为 true 可能会导致数据丢失。
- replica.lag.time.max.ms: 副本落后 Leader 的最大时间，超出该时间的副本将被视为不同步的副本。

- auto.create.topics.enable: 是否允许 Kafka 自动创建 Topic。生产者或消费者如果请求了一个不存在的 Topic，Kafka 会自动创建它。
- message.max.bytes: Kafka 生产者可以发送的消息的最大字节数。如果消息太大，会被拒绝。
- replica.fetch.max.bytes: 副本从 Leader 副本获取消息时的最大字节数。
- fetch.min.bytes: 消费者从 Kafka Broker 中获取的最小数据量（字节）。Broker 会在达到该字节数后才发送数据给消费者。
- fetch.max.wait.ms: 消费者最多等待多久以获得消息，即使没有足够的消息达到 fetch.min.bytes

- delete.topic.enable: 允许删除 Topic 的设置。如果为 false，则无法删除 Kafka 的 Topic。

- enable.auto.commit=true 时，消费者会自动定期提交它所消费的偏移量。
- auto.commit.interval.ms: 控制偏移量提交的频率。默认值通常是 5000 毫秒（5秒），这意味着每隔 5 秒，Kafka 消费者会自动提交当前的偏移量。
- auto.offset.reset: Kafka 消费者配置中的一个参数，它定义了消费者在没有可用偏移量时，或者当前偏移量在服务器上不存在（通常是因为该偏移量太老，已被 Kafka 清理掉）时应该从哪个位置开始消费消息。
  + earliest：消费者将从主题的最早的消息开始消费（也就是偏移量最小的地方）。适用于希望重新消费所有可用消息的场景。
  + latest（默认值）：消费者将从最新的消息开始消费（也就是从新生产的消息开始）。适用于希望只处理新到达的消息的场景。
  + none：如果没有找到之前提交的偏移量，消费者将抛出一个错误并停止。适用于偏移量必须存在的场景。
  + anything else：如果设置了其他无效的值，会抛出异常


## bin目录脚本

1. kafka-server-start.sh  
用于启动 Kafka Broker。这个脚本会根据给定的配置文件启动一个 Kafka 服务器。

示例：
```
bin/kafka-server-start.sh config/server.properties
```
这个命令会使用 server.properties 文件中的配置启动 Kafka 服务器。

2. kafka-server-stop.sh
用于停止 Kafka Broker。通过此脚本可以安全地关闭 Kafka 实例。

3. kafka-topics.sh
管理 Kafka 主题的脚本，可以创建、删除、列出和描述 Kafka 主题。  
```
创建主题：
bin/kafka-topics.sh --create --topic my_topic --bootstrap-server localhost:9092 --partitions 3 --replication-factor 2
创建一个名为 my_topic 的主题，设置为 3 个分区，副本因子为 2。

列出所有主题：
bin/kafka-topics.sh --list --bootstrap-server localhost:9092
列出 Kafka 集群中所有的主题。

查看主题详情：
bin/kafka-topics.sh --describe --topic my_topic --bootstrap-server localhost:9092
查看名为 my_topic 的主题的详细信息。
```

4. kafka-console-producer.sh
这是一个命令行工具，用于向 Kafka 主题发送消息。它允许你在命令行中作为生产者发送数据到 Kafka 主题。

```
bin/kafka-console-producer.sh --topic my_topic --bootstrap-server localhost:9092
启动生产者并向 my_topic 主题发送消息。在运行此命令后，终端将等待输入，你可以输入消息，按回车后消息将发送到 Kafka。
```

5. kafka-console-consumer.sh
用于从 Kafka 主题消费消息的命令行工具。它允许你在终端中作为消费者消费消息。

```
从头开始消费消息：
bin/kafka-console-consumer.sh --topic my_topic --from-beginning --bootstrap-server localhost:9092
从 my_topic 主题的开头开始消费消息。


只消费最新消息：
bin/kafka-console-consumer.sh --topic my_topic --bootstrap-server localhost:9092
仅从当前位置消费新的消息。
```

6. kafka-consumer-groups.sh
用于管理和查看 Kafka 消费者组的工具。可以查看消费者组的 Offset、Lag、成员等信息。

```
bin/kafka-consumer-groups.sh --list --bootstrap-server localhost:9092
列出集群中的所有消费者组。

查看消费者组详情：
bin/kafka-consumer-groups.sh --describe --group my_group --bootstrap-server localhost:9092
查看消费者组 my_group 的详细信息，包括 Offset 和 Lag。
```

## 消费者分组消费机制

### group.instance.id
  在 Kafka 中，group.instance.id 是消费者组中的一个配置项，主要用于实现静态成员管理（Static Membership），从而优化消费者的重新平衡过程。  

背景：  
在 Kafka 的消费者组中，重新平衡（rebalance）是当消费者加入或离开组时进行的分区重新分配操作。
然而，传统的消费者组是动态的(instance.id是动态的，会变)，消费者的生命周期是短暂的，每当消费者崩溃或断开连接时，Kafka 都会触发重新平衡。这会导致延迟和中断。  

为了解决这个问题，引入了 静态成员（Static Membership） 的概念，通过配置 group.instance.id，每个消费者在组内有一个`固定的标识符（ID）`，
即使消费者暂时断开连接，Kafka 也不会立即认为它已经离开（因为instance.id不变），而是允许它在指定的时间内重新连接，不触发重新平衡（rebalance）。  

作用：
group.instance.id：消费者在 Kafka 组中的唯一标识符。如果配置了这个值，消费者在加入组时会使用它来标识自己。即使消费者临时断开，Kafka 不会立即从组中移除它，只要它在允许的时间内重新连接，就不会触发重新平衡。  

主要优点：  
1. 减少重新平衡：当消费者短时间内断开连接后重新连接时，Kafka 不会认为该消费者已经离开，因此不会触发重新平衡（rebalance），避免消费延迟。
2. 提升可用性：在断线重连时，消费者可以继续使用之前分配的分区，而不需要重新进行分区分配。
3. 优化分区分配稳定性：使用静态成员 ID 能保证分区的所有权在短时间内不变，特别适合长时间运行的消费者。

### 如何防止client记录的offset和kafka实际的offset不一致
如果存在这种情况，可以先把kafka的offset取出来，存到redis/DB中（可以防止kafka丢失offset），
在消费kafka数据时，先比较kafka和client记录的offset，如果client.offset > kafka.offset, 说明可能消费过，kafka没把offset推进。

## 生产者拦截机制
