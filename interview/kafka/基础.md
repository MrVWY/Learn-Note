## 配置项config

- broker.id：Broker 的唯一 ID，用于标识集群中的 Kafka 节点。每个节点的 broker.id 必须唯一。
- listeners：Kafka Broker 的监听地址，指定 Kafka 应该在哪些地址和端口上监听客户端的连接。
- log.dirs: 指定存储 Kafka 数据（日志文件）的目录，支持多个目录。Kafka 会将数据存储在这些目录中。
- zookeeper.connect: 指定 ZooKeeper 集群的连接字符串，Kafka 使用 ZooKeeper 来管理集群状态。
  
- advertised.listeners: 客户端连接时使用的地址和端口，通常用于 Docker 或其他容器化环境，Broker 向客户端"广播"它的可访问地址。
- num.network.threads: Kafka 网络线程的数量，处理来自客户端的网络请求。
- num.io.threads: Kafka IO 线程的数量，处理磁盘 IO 任务。
- socket.send.buffer.bytes: Socket 发送缓冲区的大小。
- socket.receive.buffer.bytes: Socket 接收缓冲区的大小。
- socket.request.max.bytes: 客户端请求的最大字节数。

- log.retention.hours: Kafka 日志保留的最长时间，超过该时间的日志文件将被删除。可以设置为小时 (log.retention.hours) 或分钟 (log.retention.minutes)。
- log.retention.bytes: 每个 Partition 的日志最大字节数，超出该大小后 Kafka 将删除旧的日志。
- log.segment.bytes: Kafka 日志分段文件的大小。达到此大小后，Kafka 会将消息写入新的分段文件。
- log.segment.ms: 日志分段的最大时间限制。即使未达到 log.segment.bytes，也会在设定的时间间隔后分割日志文件。

- num.partitions: 创建 Topic 时的默认分区数量。
- default.replication.factor: 创建 Topic 时的默认副本因子。
- min.insync.replicas: 消息被认为成功写入的最少同步副本数量，确保数据的可靠性。
- unclean.leader.election.enable: 是否允许非同步副本被选举为 Leader。设为 true 可能会导致数据丢失。
- replica.lag.time.max.ms: 副本落后 Leader 的最大时间，超出该时间的副本将被视为不同步的副本。

- auto.create.topics.enable: 是否允许 Kafka 自动创建 Topic。生产者或消费者如果请求了一个不存在的 Topic，Kafka 会自动创建它。
- message.max.bytes: Kafka 生产者可以发送的消息的最大字节数。如果消息太大，会被拒绝。
- replica.fetch.max.bytes: 副本从 Leader 副本获取消息时的最大字节数。
- fetch.min.bytes: 消费者从 Kafka Broker 中获取的最小数据量（字节）。Broker 会在达到该字节数后才发送数据给消费者。
- fetch.max.wait.ms: 消费者最多等待多久以获得消息，即使没有足够的消息达到 fetch.min.bytes

- delete.topic.enable: 允许删除 Topic 的设置。如果为 false，则无法删除 Kafka 的 Topic。

- enable.auto.commit=true 时，消费者会自动定期提交它所消费的偏移量。
- auto.commit.interval.ms 控制偏移量提交的频率。默认值通常是 5000 毫秒（5秒），这意味着每隔 5 秒，Kafka 消费者会自动提交当前的偏移量。

## bin目录脚本

1. kafka-server-start.sh  
用于启动 Kafka Broker。这个脚本会根据给定的配置文件启动一个 Kafka 服务器。

示例：
```
bin/kafka-server-start.sh config/server.properties
```
这个命令会使用 server.properties 文件中的配置启动 Kafka 服务器。

2. kafka-server-stop.sh
用于停止 Kafka Broker。通过此脚本可以安全地关闭 Kafka 实例。

3. kafka-topics.sh
管理 Kafka 主题的脚本，可以创建、删除、列出和描述 Kafka 主题。  
```
创建主题：
bin/kafka-topics.sh --create --topic my_topic --bootstrap-server localhost:9092 --partitions 3 --replication-factor 2
创建一个名为 my_topic 的主题，设置为 3 个分区，副本因子为 2。

列出所有主题：
bin/kafka-topics.sh --list --bootstrap-server localhost:9092
列出 Kafka 集群中所有的主题。

查看主题详情：
bin/kafka-topics.sh --describe --topic my_topic --bootstrap-server localhost:9092
查看名为 my_topic 的主题的详细信息。
```

4. kafka-console-producer.sh
这是一个命令行工具，用于向 Kafka 主题发送消息。它允许你在命令行中作为生产者发送数据到 Kafka 主题。

```
bin/kafka-console-producer.sh --topic my_topic --bootstrap-server localhost:9092
启动生产者并向 my_topic 主题发送消息。在运行此命令后，终端将等待输入，你可以输入消息，按回车后消息将发送到 Kafka。
```

5. kafka-console-consumer.sh
用于从 Kafka 主题消费消息的命令行工具。它允许你在终端中作为消费者消费消息。

```
从头开始消费消息：
bin/kafka-console-consumer.sh --topic my_topic --from-beginning --bootstrap-server localhost:9092
从 my_topic 主题的开头开始消费消息。


只消费最新消息：
bin/kafka-console-consumer.sh --topic my_topic --bootstrap-server localhost:9092
仅从当前位置消费新的消息。
```

6. kafka-consumer-groups.sh
用于管理和查看 Kafka 消费者组的工具。可以查看消费者组的 Offset、Lag、成员等信息。

```
bin/kafka-consumer-groups.sh --list --bootstrap-server localhost:9092
列出集群中的所有消费者组。

查看消费者组详情：
bin/kafka-consumer-groups.sh --describe --group my_group --bootstrap-server localhost:9092
查看消费者组 my_group 的详细信息，包括 Offset 和 Lag。
```


